{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C4Va5H1Rut7"
      },
      "source": [
        "Write a python code to launch a video file from google drive, then open it, run it from the 11th second, make snapshots once every second and save the images as PNG files in the 'output_images' directory, resize each image to 640x640 pixels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWuSDearRy3C"
      },
      "source": [
        "To achieve this task, you can use the following Python code. This code will:\n",
        "\n",
        "Download a video file from Google Drive.\n",
        "Open and play the video starting from the 11th second.\n",
        "Capture snapshots every second and save them as PNG files in the 'output_images' directory.\n",
        "Resize each image to 640x640 pixels.\n",
        "Before running this code, make sure you have the necessary libraries installed. You can install them using pip install pydrive2 opencv-python pillow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeyaLyttSh6i",
        "outputId": "82999279-ddcb-482b-d49b-afa5ca88b804"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from io import BytesIO\n",
        "import cv2\n",
        "import time\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from PIL import Image\n",
        "!pip install opencv-python\n",
        "\n",
        "import gdown  # Import gdown library\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "import hashlib\n",
        "import shutil\n",
        "import requests\n",
        "import numpy as np\n",
        "import gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Wn1m0yQf8RI"
      },
      "outputs": [],
      "source": [
        "# Google Drive file URL (make sure it's publicly accessible)\n",
        "file_url = 'https://drive.google.com/file/d/1G5UE0ntpPepY1fi2PHR082CbbffQH1ZG/view?usp=sharing'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gicr5fVNG5iL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c77597a4-e2c8-4ce1-9811-7c1cf411711f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a code in python to extract files from a video from file_url = 'https://drive.google.com/file/d/1epp3I2VnmRrwG-ZewUdgijoM4jGxcTp9/view?usp=sharing' at a rate of 1 snapshot per second then save the images to one folder in PNG format. Then copy these images to the second folder but identify similar images and copy only the first image from the streaks of the similar images. Then split the images from the second folder into multiple images of the size 640 * 640 pixels and save these into the third folder.Use gdown to download the video."
      ],
      "metadata": {
        "id": "K2N-eqgy3R_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract frames from a video and save them to a folder\n",
        "def extract_frames_from_video(video_path, output_folder, frame_rate=1):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Open the video file\n",
        "    video_capture = cv2.VideoCapture(video_path)\n",
        "\n",
        "    frame_number = 0\n",
        "    while True:\n",
        "        ret, frame = video_capture.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Extract frames at the specified frame rate\n",
        "        if frame_number % frame_rate == 0:\n",
        "            frame_filename = os.path.join(output_folder, f\"frame_{frame_number}.png\")\n",
        "            cv2.imwrite(frame_filename, frame)\n",
        "\n",
        "        frame_number += 1\n",
        "\n",
        "    video_capture.release()\n",
        "\n",
        "# Function to calculate an image hash\n",
        "def calculate_image_hash(image_path):\n",
        "    image = Image.open(image_path)\n",
        "    image_hash = hashlib.md5(np.array(image)).hexdigest()\n",
        "    return image_hash\n",
        "\n",
        "# Function to copy unique frames to a destination folder\n",
        "def copy_unique_frames(source_folder, destination_folder):\n",
        "    # Create the destination folder if it doesn't exist\n",
        "    if not os.path.exists(destination_folder):\n",
        "        os.makedirs(destination_folder)\n",
        "\n",
        "    # Create a dictionary to store image hashes and their corresponding file paths\n",
        "    image_hashes = {}\n",
        "\n",
        "    for root, _, files in os.walk(source_folder):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "\n",
        "            # Calculate the hash of the image\n",
        "            hash_value = calculate_image_hash(file_path)\n",
        "\n",
        "            # Check if the hash is already in the dictionary (indicating a duplicate)\n",
        "            if hash_value not in image_hashes:\n",
        "                image_hashes[hash_value] = file_path\n",
        "\n",
        "    for hash_value, file_path in image_hashes.items():\n",
        "        destination_path = os.path.join(destination_folder, os.path.basename(file_path))\n",
        "        shutil.copy(file_path, destination_path)\n",
        "\n",
        "# Function to split images into 640x640 segments and save them\n",
        "def split_images(input_folder, output_folder, target_size=(640, 640)):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for root, _, files in os.walk(input_folder):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "\n",
        "            # Read the image\n",
        "            image = cv2.imread(file_path)\n",
        "\n",
        "            # Get the image dimensions\n",
        "            height, width, _ = image.shape\n",
        "\n",
        "            # Calculate the number of rows and columns for splitting\n",
        "            rows = height // target_size[0]\n",
        "            cols = width // target_size[1]\n",
        "\n",
        "            for i in range(rows):\n",
        "                for j in range(cols):\n",
        "                    # Calculate the cropping coordinates\n",
        "                    y1 = i * target_size[0]\n",
        "                    y2 = (i + 1) * target_size[0]\n",
        "                    x1 = j * target_size[1]\n",
        "                    x2 = (j + 1) * target_size[1]\n",
        "\n",
        "                    # Crop the image segment\n",
        "                    segment = image[y1:y2, x1:x2]\n",
        "\n",
        "                    # Save the cropped segment\n",
        "                    segment_filename = os.path.join(output_folder, f\"{file}_segment_{i}_{j}.png\")\n",
        "                    cv2.imwrite(segment_filename, segment)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Define folder paths, the part in the Google drive shared link between /d/ and /view?\n",
        "    file_url = 'https://drive.google.com/file/d/1G5UE0ntpPepY1fi2PHR082CbbffQH1ZG/view?usp=sharing'\n",
        "    first_folder = \"first_folder\"\n",
        "    second_folder = \"second_folder\"\n",
        "    third_folder = \"third_folder\"\n",
        "\n",
        "    # Download the video file using gdown\n",
        "    gdown.download(file_url, \"downloaded_video.mp4\", quiet=False)\n",
        "\n",
        "    # Step 1: Extract frames from the video\n",
        "    extract_frames_from_video(\"downloaded_video.mp4\", first_folder)\n",
        "\n",
        "    # Step 2: Copy unique frames to the second folder\n",
        "    copy_unique_frames(first_folder, second_folder)\n",
        "\n",
        "    # Step 3: Split images in the second folder into 640x640 segments and save to the third folder\n",
        "    split_images(second_folder, third_folder, target_size=(640, 640))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2T47MlTwmCt",
        "outputId": "a65c1b0e-8a3e-4bcb-bd90-3ad9a560d9f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1epp3I2VnmRrwG-ZewUdgijoM4jGxcTp9\n",
            "To: /content/downloaded_video.mp4\n",
            "100%|██████████| 218M/218M [00:07<00:00, 27.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's how the algorithm works:\n",
        "\n",
        "\n",
        "1.   It defines a function calculate_image_hash that computes an MD5 hash of the grayscale version of an image.\n",
        "2.  It defines a function find_duplicate_images that searches for duplicate images in a specified folder. It iterates through all the files in the folder, calculates the hash for each image, and checks if the hash already exists in a dictionary. If it does, the file is considered a duplicate and is deleted. Otherwise, the hash and file path are stored in the dictionary.\n",
        "\n",
        "3. In the main part of the code, replace \"path_to_your_folder_with_images\" with the actual path to the folder containing your images.\n",
        "\n",
        "\n",
        "4. When you run the script, it will identify and delete duplicate images in the specified folder, keeping only the first one encountered in each streak of duplicates.\n",
        "\n",
        "Please be cautious when using this script, and make sure to back up your images before running it, as it will permanently delete duplicate images.\n"
      ],
      "metadata": {
        "id": "cucJ3QPZnKro"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}